{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filepath = \"./spotify_million_playlist_dataset/data\"\n",
    "filename = filepath + \"/mpd.slice.0-999.json\"\n",
    "\n",
    "MAXPLAYLISTSIZE = 999999\n",
    "MAXREADFILES = 10000\n",
    "PLAYLISTPERFILE = 1000\n",
    "\n",
    "# Input: filesToRead(int) number of files to read\n",
    "# Add error handling later\n",
    "def readFile(filesToRead):\n",
    "    playlistNames = []\n",
    "    playlistTracksIds = []\n",
    "    playlistArtistIds = []\n",
    "    playlistAlbumIds = []\n",
    "    for slice_number in range(filesToRead):\n",
    "        filename = filepath + \"/mpd.slice.\" + str(slice_number*PLAYLISTPERFILE) + \"-\" + str((slice_number*PLAYLISTPERFILE)+PLAYLISTPERFILE-1) + \".json\"\n",
    "        print(filename)\n",
    "        \n",
    "        with open(filename, 'r') as file:\n",
    "            playlist_data = json.load(file)\n",
    "\n",
    "        listOfPlayLists = playlist_data['playlists']\n",
    "\n",
    "        for playlist in listOfPlayLists:\n",
    "            playlistNames.append(playlist['name'])\n",
    "            trackIds = [track['track_uri'] for track in playlist['tracks']]\n",
    "            playlistTracksIds.append(trackIds)\n",
    "            artistIds = [artist['artist_uri'] for artist in playlist['tracks']]\n",
    "            playlistArtistIds.append(artistIds)\n",
    "            albumIds = [album['album_uri'] for album in playlist['tracks']]\n",
    "            playlistAlbumIds.append(albumIds)\n",
    "    return pd.DataFrame({'name': playlistNames, 'trackIds': playlistTracksIds, 'artistIds': playlistArtistIds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./spotify_million_playlist_dataset/data/mpd.slice.0-999.json\n",
      "./spotify_million_playlist_dataset/data/mpd.slice.1000-1999.json\n",
      "./spotify_million_playlist_dataset/data/mpd.slice.2000-2999.json\n",
      "./spotify_million_playlist_dataset/data/mpd.slice.3000-3999.json\n",
      "./spotify_million_playlist_dataset/data/mpd.slice.4000-4999.json\n",
      "./spotify_million_playlist_dataset/data/mpd.slice.5000-5999.json\n",
      "./spotify_million_playlist_dataset/data/mpd.slice.6000-6999.json\n",
      "./spotify_million_playlist_dataset/data/mpd.slice.7000-7999.json\n",
      "./spotify_million_playlist_dataset/data/mpd.slice.8000-8999.json\n",
      "./spotify_million_playlist_dataset/data/mpd.slice.9000-9999.json\n"
     ]
    }
   ],
   "source": [
    "# Get data \n",
    "playListDF = readFile(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the songs \n",
    "explodedTracks = playListDF.explode('trackIds')\n",
    "uniqueTracks = explodedTracks['trackIds'].unique()\n",
    "# Construct a binary matrix with rows=playlists and columns=songs\n",
    "tracksMatrix = pd.DataFrame(0, index=range(len(playListDF)), columns=uniqueTracks)\n",
    "for i, playlist in playListDF.iterrows():\n",
    "    for tracks in playlist['trackIds']:\n",
    "        tracksMatrix.loc[i, tracks] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the size of the matrix\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "tracksMatrixSparse = csr_matrix(tracksMatrix.values)\n",
    "tracksMatrixCOO = tracksMatrixSparse.tocoo()\n",
    "tracksMatrixCOO = pd.DataFrame({'playlistId': tracksMatrixCOO.row, 'trackId':tracksMatrixCOO.col, 'inPlaylist':tracksMatrixCOO.data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "RMSE: 0.0107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010715237242704812"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(tracksMatrixCOO, reader)\n",
    "\n",
    "trainset, testset = train_test_split(data)\n",
    "\n",
    "model = SVD(biased=True, n_epochs=30, lr_all=0.01, reg_all=0.1, verbose=True)\n",
    "model.fit(trainset)\n",
    "\n",
    "predictions = model.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopPredictions(model, playlist_id, numPredictions):\n",
    "    # Get all item IDs in the dataset\n",
    "    item_ids = set([iid for (_, iid, _) in trainset.all_items()])\n",
    "\n",
    "    # Predict ratings for all items for the given user\n",
    "    predictions = [(iid, model.predict(playlist_id, iid).est) for iid in item_ids]\n",
    "\n",
    "    # Sort the predictions by predicted rating in descending order\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract the top-N item IDs from the sorted predictions\n",
    "    top_n = [iid for (iid, _) in predictions[:numPredictions]]\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(recommended_items, ground_truth):\n",
    "    # Calculate the number of overlapping items between recommended items and ground truth\n",
    "    overlapping_items = set(recommended_items) & set(ground_truth)\n",
    "    \n",
    "    # Calculate precision: Number of overlapping items / Total number of recommended items\n",
    "    if len(recommended_items) > 0:\n",
    "        precision = len(overlapping_items) / len(recommended_items)\n",
    "    else:\n",
    "        precision = 0.0  # Handle the case when there are no recommended items\n",
    "\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m [iid \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, _) \u001b[38;5;129;01min\u001b[39;00m testset \u001b[38;5;28;01mif\u001b[39;00m uid \u001b[38;5;241m==\u001b[39m playlistId]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Generate recommendations for the user\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mgetTopPredictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplaylistId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Calculate precision by comparing the recommended items with the ground truth\u001b[39;00m\n\u001b[0;32m     18\u001b[0m precision \u001b[38;5;241m=\u001b[39m calculate_precision(recommendations, ground_truth)\n",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m, in \u001b[0;36mgetTopPredictions\u001b[1;34m(model, playlist_id, numPredictions)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetTopPredictions\u001b[39m(model, playlist_id, numPredictions):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Get all item IDs in the dataset\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     item_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43m[\u001b[49m\u001b[43miid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Predict ratings for all items for the given user\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [(iid, model\u001b[38;5;241m.\u001b[39mpredict(playlist_id, iid)\u001b[38;5;241m.\u001b[39mest) \u001b[38;5;28;01mfor\u001b[39;00m iid \u001b[38;5;129;01min\u001b[39;00m item_ids]\n",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetTopPredictions\u001b[39m(model, playlist_id, numPredictions):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Get all item IDs in the dataset\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     item_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([iid \u001b[38;5;28;01mfor\u001b[39;00m (_, iid, _) \u001b[38;5;129;01min\u001b[39;00m trainset\u001b[38;5;241m.\u001b[39mall_items()])\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Predict ratings for all items for the given user\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [(iid, model\u001b[38;5;241m.\u001b[39mpredict(playlist_id, iid)\u001b[38;5;241m.\u001b[39mest) \u001b[38;5;28;01mfor\u001b[39;00m iid \u001b[38;5;129;01min\u001b[39;00m item_ids]\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "# Lets test using R-precision as used in the Spotify Million Dollar Playset Challenge\n",
    "# Get the list of unique user IDs in the test set\n",
    "playlistIds = set([uid for (uid, _, _) in testset])\n",
    "\n",
    "# Initialize variables to store precision values\n",
    "total_precision = 0\n",
    "total_users = 0\n",
    "\n",
    "# Calculate R-Precision for each user in the test set\n",
    "for playlistId in playlistIds:\n",
    "    # Get the list of items the user has interacted with (ground truth)\n",
    "    ground_truth = [iid for (uid, iid, _) in testset if uid == playlistId]\n",
    "\n",
    "    # Generate recommendations for the user\n",
    "    recommendations = getTopPredictions(model, playlistId, 10)\n",
    "\n",
    "    # Calculate precision by comparing the recommended items with the ground truth\n",
    "    precision = calculate_precision(recommendations, ground_truth)\n",
    "\n",
    "    # Update total precision and total users\n",
    "    total_precision += precision\n",
    "    total_users += 1\n",
    "\n",
    "# Calculate average precision (R-Precision)\n",
    "r_precision = total_precision / total_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtestset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
